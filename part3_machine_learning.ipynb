{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7844f24",
   "metadata": {},
   "source": [
    "# Assignment 3 Natural Language Processing - Part 2: traditional machine learning approach: XGBoost\n",
    "\n",
    "In this part of the assignment, we explore the possibilities of multilingual and cross-lingual modelling when traditional machine learning methods are used. Multilingual and cross-lingual models differ, therefore we decided to also look at them separately in this part.\n",
    "\n",
    "Firstly, we look into cross-lingual models. Cross-lingual models are models that are trained on texts in a certain language that can predict when given another language. Given this, we identified two possible options for exploring this:\n",
    "\n",
    "- we train a model using the English text corpus and validate it using the Dutch text corpus. \n",
    "- After this, we switch the languages. This means that we then train the model on the Dutch text corpus and validate it using the English text corpus. \n",
    "\n",
    "We can then compare the performances of these models to see how they compare and what the effects of the Dutch and English languages have on each other and the predictions.\n",
    "\n",
    "Secondly, we investigate the potential of the multilingual models. Multilingual models are models that take as input texts in different languages. Given this we again identified 2 approaches we could take:\n",
    "\n",
    "- As we have both the English and Dutch versions of the texts, we concatenate the two texts into one big text that consists of both the English and Dutch versions of that text. This we can then feed into a model. The model will thus have a larger document text as input.\n",
    "- As a second option we add the Dutch text with respective target variables to the English dataset. This way we enlarge the English Dataset. The model will thus have more documents as input and will be trained on both English and Dutch.\n",
    "\n",
    "As with the cross-lingual, we can then compare the performances of these models against each other.\n",
    "\n",
    "For the machine learner, we decided to use an XGBoost regressor with ‘binary:logistic’ objective function again due to its performance compared to SVM. As a vectorisation technique, we used TF-IDF as in part 2 it became clear that, although performance is not great, this technique was able to show the highest F1 scores if we trained the model to predict 5 target variables in one go. For parameters, we do hyperparameter tuning to find the optimal set of parameters for the XGBoost model.\n",
    "\n",
    "As with the other parts, we used the F1 score as the main performance metric but also determined the ROC AUC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85325eac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maxma\\anaconda3\\envs\\nlp\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, RepeatedKFold\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import xgboost as xgb\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a67a51d",
   "metadata": {},
   "source": [
    "# Cross-lingual\n",
    "\n",
    "first we determine the performance of the cross-lingual methods by training with the English text and validating with the Dutch text, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fabc9cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = pd.read_csv('processed_data_english_no_lowercasing.csv')\n",
    "nl = pd.read_csv('processed_data_dutch_no_lowercasing.csv')\n",
    "nl = nl.rename(columns={'TEXT_NL': 'TEXT'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f778da1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train = eng['TEXT'].tolist()\n",
    "y_train_eng_nl = eng[['cEXT', 'cNEU', 'cAGR', 'cCON', 'cOPN']]\n",
    "\n",
    "corpus_test = nl['TEXT'].tolist()\n",
    "y_test_eng_nl = eng[['cEXT', 'cNEU', 'cAGR', 'cCON', 'cOPN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "189e0ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()  \n",
    "\n",
    "# for Ext\n",
    "X_train_eng_nl = tfidf.fit_transform(corpus_train)\n",
    "X_test_eng_nl = tfidf.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12b293ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_param_t = {'learning_rate': 0.01, 'lambda': 0.01, 'gamma': 0.1, 'alpha': 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fa973ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB_model(X_train, X_test, y_train, y_test, opt_params):\n",
    "    xgb_model = xgb.XGBRegressor(objective='binary:logistic', \n",
    "                                reg_lambda=opt_params['lambda'], \n",
    "                                alpha=opt_params['alpha'], \n",
    "                                learning_rate=opt_params['learning_rate'], \n",
    "                                gamma=opt_params['gamma'],\n",
    "                                eval_metric='rmse')\n",
    "    \n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    predictions_prob = xgb_model.predict(X_test)\n",
    "\n",
    "    predictions_binary = (predictions_prob > 0.5).astype(int)\n",
    "    \n",
    "    f1 = f1_score(y_test.values.flatten(), predictions_binary.flatten(), average='micro')\n",
    "    print('F1 Score:', f1)\n",
    "\n",
    "    auc_roc = roc_auc_score(y_test.values.flatten(), predictions_prob.flatten(), average='micro')\n",
    "    print('AUC/ROC:', auc_roc)\n",
    "    \n",
    "    return [f1, auc_roc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5eb12d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5044211947350659\n",
      "AUC/ROC: 0.5250265708475865\n"
     ]
    }
   ],
   "source": [
    "# English with Dutch validation\n",
    "metrics_eng_nl = XGB_model(X_train_eng_nl, X_test_eng_nl, y_train_eng_nl, y_test_eng_nl, opt_param_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7de7d9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5455956800539993\n",
      "AUC/ROC: 0.5635992984231872\n"
     ]
    }
   ],
   "source": [
    "# Dutch with English validation\n",
    "metrics_nl_eng = XGB_model(X_test_eng_nl, X_train_eng_nl, y_test_eng_nl, y_train_eng_nl, opt_param_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc51c6a",
   "metadata": {},
   "source": [
    "# Multi-lingual\n",
    "\n",
    "As second part, we determine the performance of training a model that gets text in multiple languages. As mentioned, we try 2 methods for doing so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78205f85",
   "metadata": {},
   "source": [
    "## Concatenating\n",
    "\n",
    "The first method is to paste the Dutch texts to the English texts, enlarging the text that the model will get as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8fbc7e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>TEXT_NL</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well right woke midday nap Its sort weird ever...</td>\n",
       "      <td>Nou moment net wakker middagdutje Het beetje r...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well stream consciousness essay used thing lik...</td>\n",
       "      <td>Nou gaan stroom bewustzijn essay deed soort di...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>open keyboard button push The thing finally wo...</td>\n",
       "      <td>Een open toetsenbord knoppen drukken Het ding ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cant believe Its really happening pulse racing...</td>\n",
       "      <td>geloven Het gebeurt echt Mijn pol raast gek Du...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well good old stream consciousness assignment ...</td>\n",
       "      <td>Welnu weer goede oude stroom bewustzijnstoewij...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>motivated day day basis need provide little fa...</td>\n",
       "      <td>word dagelijks gemotiveerd noodzaak kleine gez...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>son biggest part life without reckless person ...</td>\n",
       "      <td>Mijn zoon grootste deel leven gewoon roekeloze...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>kid grandkids keep motivated everyday inspire ...</td>\n",
       "      <td>Mijn kinderen kleinkinderen houden elke dag ge...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>biggest drive earn money retire beach schedule...</td>\n",
       "      <td>Mijn grootste drijfveer geld verdienen zodat p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>People never give cause life cruel strong enem...</td>\n",
       "      <td>Mensen nooit opgeven leven grootste deel tijd ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2963 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   TEXT  \\\n",
       "0     Well right woke midday nap Its sort weird ever...   \n",
       "1     Well stream consciousness essay used thing lik...   \n",
       "2     open keyboard button push The thing finally wo...   \n",
       "3     cant believe Its really happening pulse racing...   \n",
       "4     Well good old stream consciousness assignment ...   \n",
       "...                                                 ...   \n",
       "2958  motivated day day basis need provide little fa...   \n",
       "2959  son biggest part life without reckless person ...   \n",
       "2960  kid grandkids keep motivated everyday inspire ...   \n",
       "2961  biggest drive earn money retire beach schedule...   \n",
       "2962  People never give cause life cruel strong enem...   \n",
       "\n",
       "                                                TEXT_NL  cEXT  cNEU  cAGR  \\\n",
       "0     Nou moment net wakker middagdutje Het beetje r...     0     1     1   \n",
       "1     Nou gaan stroom bewustzijn essay deed soort di...     0     0     1   \n",
       "2     Een open toetsenbord knoppen drukken Het ding ...     0     1     0   \n",
       "3     geloven Het gebeurt echt Mijn pol raast gek Du...     1     0     1   \n",
       "4     Welnu weer goede oude stroom bewustzijnstoewij...     1     0     1   \n",
       "...                                                 ...   ...   ...   ...   \n",
       "2958  word dagelijks gemotiveerd noodzaak kleine gez...     1     0     0   \n",
       "2959  Mijn zoon grootste deel leven gewoon roekeloze...     1     1     0   \n",
       "2960  Mijn kinderen kleinkinderen houden elke dag ge...     1     0     1   \n",
       "2961  Mijn grootste drijfveer geld verdienen zodat p...     0     0     0   \n",
       "2962  Mensen nooit opgeven leven grootste deel tijd ...     1     1     0   \n",
       "\n",
       "      cCON  cOPN  \n",
       "0        0     1  \n",
       "1        0     0  \n",
       "2        1     1  \n",
       "3        1     0  \n",
       "4        0     1  \n",
       "...    ...   ...  \n",
       "2958     1     1  \n",
       "2959     0     0  \n",
       "2960     1     0  \n",
       "2961     0     0  \n",
       "2962     0     0  \n",
       "\n",
       "[2963 rows x 7 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('processed_data_full_no_lowercasing.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b40c19c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nou moment net wakker middagdutje Het beetje raar sind Texas verhuisde problemen gehad concentreren dingen herinner huiswerk klas begon zodra klok sloeg stopte totdat klaar Natuurlijk gemakkelijker deed steed Maar hierheen verhuisde huiswerk beetje uitdagender druk werk besloot uren besteden gewoon redden Maar ding klas oplette gewoon spul kende terugkijk echt hard gewerkt afgelopen twee jaar goede spoor gebleven lui genie hey allemaal goed Het laat verleden corrigeren weet echt toekomst gefocust blijven Het enige weet wanneer mensen zeggen campus wonen concentreren Voor gemakkelijker helaas woon thuis waakzame oog ouders klein zeurend zusje alleen zeurt zeurt begrijpt bedoel Een ander ding gewoon gedoe helemaal terug school moeten gaan gewoon bibliotheek gaan studeren verhuizen weet vertellen Begrijp verkeerd zie waar vandaan komen waarom willen verhuis weggaan alleen zoveel beschermd maak zorgen wereld Het enige vragen kamer schoon houden toe helpen bedrijf Maar wel Maar genoeg geld volgend semester slaapzaal appartement wonen denk gebruik maken Maar onderwerp ging gisteravond sixth street geweldig lang weet waarom zoveel Austin hou Toen woonde ging geweldig rennen zoveel studenten nachts rond gewoon plezier weet verantwoordelijk genoeg plezier prioriteiten recht houden Thuiswonend helemaal uitgaan vragen waar waarom wanneer kom terug vragen wou alleen keer verantwoordelijke persoon behandeld zu verpest gek zodra universiteit ging hele universiteitscarrire verknoeide feesten ultieme reden willen plezier maken Maar weinig moeten laten gaan wereld verkennen Indisch Indiase cultuur Indiase waarden druisen plezier bedoel zin mensen ontmoeten uitgaan mensen feesten gewoon plezier maken Mijn school moeilijk manier denk vrijheid druk zetten beter presteren school ouders uiteindelijk verwacht mezelf Wel leuk schrijven weet schrijven kunt halen geholpen aantal gedachten orde brengen Dus hoop leuk vond lezen succes TAs'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TEXT_NL'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d6c2ee0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>TEXT_NL</th>\n",
       "      <th>TEXT_COMBINED</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well right woke midday nap Its sort weird ever...</td>\n",
       "      <td>Nou moment net wakker middagdutje Het beetje r...</td>\n",
       "      <td>Well right woke midday nap Its sort weird ever...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well stream consciousness essay used thing lik...</td>\n",
       "      <td>Nou gaan stroom bewustzijn essay deed soort di...</td>\n",
       "      <td>Well stream consciousness essay used thing lik...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>open keyboard button push The thing finally wo...</td>\n",
       "      <td>Een open toetsenbord knoppen drukken Het ding ...</td>\n",
       "      <td>open keyboard button push The thing finally wo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cant believe Its really happening pulse racing...</td>\n",
       "      <td>geloven Het gebeurt echt Mijn pol raast gek Du...</td>\n",
       "      <td>cant believe Its really happening pulse racing...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well good old stream consciousness assignment ...</td>\n",
       "      <td>Welnu weer goede oude stroom bewustzijnstoewij...</td>\n",
       "      <td>Well good old stream consciousness assignment ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>motivated day day basis need provide little fa...</td>\n",
       "      <td>word dagelijks gemotiveerd noodzaak kleine gez...</td>\n",
       "      <td>motivated day day basis need provide little fa...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>son biggest part life without reckless person ...</td>\n",
       "      <td>Mijn zoon grootste deel leven gewoon roekeloze...</td>\n",
       "      <td>son biggest part life without reckless person ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>kid grandkids keep motivated everyday inspire ...</td>\n",
       "      <td>Mijn kinderen kleinkinderen houden elke dag ge...</td>\n",
       "      <td>kid grandkids keep motivated everyday inspire ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>biggest drive earn money retire beach schedule...</td>\n",
       "      <td>Mijn grootste drijfveer geld verdienen zodat p...</td>\n",
       "      <td>biggest drive earn money retire beach schedule...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>People never give cause life cruel strong enem...</td>\n",
       "      <td>Mensen nooit opgeven leven grootste deel tijd ...</td>\n",
       "      <td>People never give cause life cruel strong enem...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2963 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   TEXT  \\\n",
       "0     Well right woke midday nap Its sort weird ever...   \n",
       "1     Well stream consciousness essay used thing lik...   \n",
       "2     open keyboard button push The thing finally wo...   \n",
       "3     cant believe Its really happening pulse racing...   \n",
       "4     Well good old stream consciousness assignment ...   \n",
       "...                                                 ...   \n",
       "2958  motivated day day basis need provide little fa...   \n",
       "2959  son biggest part life without reckless person ...   \n",
       "2960  kid grandkids keep motivated everyday inspire ...   \n",
       "2961  biggest drive earn money retire beach schedule...   \n",
       "2962  People never give cause life cruel strong enem...   \n",
       "\n",
       "                                                TEXT_NL  \\\n",
       "0     Nou moment net wakker middagdutje Het beetje r...   \n",
       "1     Nou gaan stroom bewustzijn essay deed soort di...   \n",
       "2     Een open toetsenbord knoppen drukken Het ding ...   \n",
       "3     geloven Het gebeurt echt Mijn pol raast gek Du...   \n",
       "4     Welnu weer goede oude stroom bewustzijnstoewij...   \n",
       "...                                                 ...   \n",
       "2958  word dagelijks gemotiveerd noodzaak kleine gez...   \n",
       "2959  Mijn zoon grootste deel leven gewoon roekeloze...   \n",
       "2960  Mijn kinderen kleinkinderen houden elke dag ge...   \n",
       "2961  Mijn grootste drijfveer geld verdienen zodat p...   \n",
       "2962  Mensen nooit opgeven leven grootste deel tijd ...   \n",
       "\n",
       "                                          TEXT_COMBINED  cEXT  cNEU  cAGR  \\\n",
       "0     Well right woke midday nap Its sort weird ever...     0     1     1   \n",
       "1     Well stream consciousness essay used thing lik...     0     0     1   \n",
       "2     open keyboard button push The thing finally wo...     0     1     0   \n",
       "3     cant believe Its really happening pulse racing...     1     0     1   \n",
       "4     Well good old stream consciousness assignment ...     1     0     1   \n",
       "...                                                 ...   ...   ...   ...   \n",
       "2958  motivated day day basis need provide little fa...     1     0     0   \n",
       "2959  son biggest part life without reckless person ...     1     1     0   \n",
       "2960  kid grandkids keep motivated everyday inspire ...     1     0     1   \n",
       "2961  biggest drive earn money retire beach schedule...     0     0     0   \n",
       "2962  People never give cause life cruel strong enem...     1     1     0   \n",
       "\n",
       "      cCON  cOPN  \n",
       "0        0     1  \n",
       "1        0     0  \n",
       "2        1     1  \n",
       "3        1     0  \n",
       "4        0     1  \n",
       "...    ...   ...  \n",
       "2958     1     1  \n",
       "2959     0     0  \n",
       "2960     1     0  \n",
       "2961     0     0  \n",
       "2962     0     0  \n",
       "\n",
       "[2963 rows x 8 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TEXT_COMBINED'] = df['TEXT'] + ' ' + df['TEXT_NL']\n",
    "df = df[['TEXT', 'TEXT_NL',  'TEXT_COMBINED', 'cEXT', 'cNEU', 'cAGR', 'cCON', 'cOPN']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1788e956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well right woke midday nap Its sort weird ever since moved Texas problem concentrating thing remember starting homework grade soon clock struck stopping done course easier still But moved homework got little challenging lot busy work decided spend hour getting But thing always paid attention class plain knew stuff look back really worked hard stayed track last two year without getting lazy would genius hey thats good Its late correct past dont really know stay focused future The one thing know people say live campus cant concentrate For would easier ala living home watchful eye parent little nagging sister nag nag nag You get point Another thing hassle way back school library study need move dont know tell Dont get wrong see theyre coming dont want move need get away Theyve sheltered much dont worry world The thing ask keep room clean help business cant even But need But got enough money live dorm apartment next semester think Ill take advantage But topic went sixth street last night blast havent long Now know love Austin much When lived used time blast many student running around night want fun know responsible enough able fun keep priority straight Living home cant without asking coming back question wish could treated like responsible person sister screwed She went crazy second moved college messed whole college career partying much And thats ultimate reason dont want fun But little anymore need let explore world Indian Indian culture Indian value They fun mean sense meeting people going people partying plain fun school difficult already somehow think freedom put pressure better school thats parent ultimately expect Well fun writing dont know anything writing helped get thought order hope fun reading good luck TAs Nou moment net wakker middagdutje Het beetje raar sind Texas verhuisde problemen gehad concentreren dingen herinner huiswerk klas begon zodra klok sloeg stopte totdat klaar Natuurlijk gemakkelijker deed steed Maar hierheen verhuisde huiswerk beetje uitdagender druk werk besloot uren besteden gewoon redden Maar ding klas oplette gewoon spul kende terugkijk echt hard gewerkt afgelopen twee jaar goede spoor gebleven lui genie hey allemaal goed Het laat verleden corrigeren weet echt toekomst gefocust blijven Het enige weet wanneer mensen zeggen campus wonen concentreren Voor gemakkelijker helaas woon thuis waakzame oog ouders klein zeurend zusje alleen zeurt zeurt begrijpt bedoel Een ander ding gewoon gedoe helemaal terug school moeten gaan gewoon bibliotheek gaan studeren verhuizen weet vertellen Begrijp verkeerd zie waar vandaan komen waarom willen verhuis weggaan alleen zoveel beschermd maak zorgen wereld Het enige vragen kamer schoon houden toe helpen bedrijf Maar wel Maar genoeg geld volgend semester slaapzaal appartement wonen denk gebruik maken Maar onderwerp ging gisteravond sixth street geweldig lang weet waarom zoveel Austin hou Toen woonde ging geweldig rennen zoveel studenten nachts rond gewoon plezier weet verantwoordelijk genoeg plezier prioriteiten recht houden Thuiswonend helemaal uitgaan vragen waar waarom wanneer kom terug vragen wou alleen keer verantwoordelijke persoon behandeld zu verpest gek zodra universiteit ging hele universiteitscarrire verknoeide feesten ultieme reden willen plezier maken Maar weinig moeten laten gaan wereld verkennen Indisch Indiase cultuur Indiase waarden druisen plezier bedoel zin mensen ontmoeten uitgaan mensen feesten gewoon plezier maken Mijn school moeilijk manier denk vrijheid druk zetten beter presteren school ouders uiteindelijk verwacht mezelf Wel leuk schrijven weet schrijven kunt halen geholpen aantal gedachten orde brengen Dus hoop leuk vond lezen succes TAs'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TEXT_COMBINED'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "65080c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df['TEXT_COMBINED'].tolist()\n",
    "y = df[['cEXT', 'cNEU', 'cAGR', 'cCON', 'cOPN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8c6d4d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(corpus, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0bf564b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()  \n",
    "X_train_t = tfidf.fit_transform(X_train_t)\n",
    "X_test_t = tfidf.transform(X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b7f0c60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To not show the Sklearn warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "827fbeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV 1/2] END alpha=1.0, gamma=1.0, lambda=1.0, learning_rate=0.2; f1: (test=nan) roc_auc: (test=0.583) total time=  45.4s\n",
      "[CV 2/2] END alpha=1.0, gamma=1.0, lambda=1.0, learning_rate=0.2; f1: (test=nan) roc_auc: (test=0.556) total time=  44.5s\n",
      "[CV 1/2] END alpha=1.0, gamma=1.0, lambda=1.0, learning_rate=0.01; f1: (test=nan) roc_auc: (test=0.574) total time= 2.0min\n",
      "[CV 2/2] END alpha=1.0, gamma=1.0, lambda=1.0, learning_rate=0.01; f1: (test=nan) roc_auc: (test=0.553) total time= 2.0min\n",
      "[CV 1/2] END alpha=0.01, gamma=1.0, lambda=0.01, learning_rate=0.01; f1: (test=nan) roc_auc: (test=0.572) total time= 1.6min\n",
      "[CV 2/2] END alpha=0.01, gamma=1.0, lambda=0.01, learning_rate=0.01; f1: (test=nan) roc_auc: (test=0.549) total time= 1.7min\n",
      "[CV 1/2] END alpha=0.01, gamma=1.0, lambda=1.0, learning_rate=0.01; f1: (test=nan) roc_auc: (test=0.575) total time= 2.0min\n",
      "[CV 2/2] END alpha=0.01, gamma=1.0, lambda=1.0, learning_rate=0.01; f1: (test=nan) roc_auc: (test=0.549) total time= 2.0min\n",
      "[CV 1/2] END alpha=0.1, gamma=1.0, lambda=0.01, learning_rate=0.2; f1: (test=nan) roc_auc: (test=0.566) total time= 1.0min\n",
      "[CV 2/2] END alpha=0.1, gamma=1.0, lambda=0.01, learning_rate=0.2; f1: (test=nan) roc_auc: (test=0.549) total time=  56.0s\n",
      "[CV 1/2] END alpha=0.01, gamma=0.01, lambda=1.0, learning_rate=0.2; f1: (test=nan) roc_auc: (test=0.575) total time= 2.0min\n",
      "[CV 2/2] END alpha=0.01, gamma=0.01, lambda=1.0, learning_rate=0.2; f1: (test=nan) roc_auc: (test=0.554) total time= 2.1min\n",
      "[CV 1/2] END alpha=1.0, gamma=0.1, lambda=1.0, learning_rate=0.2; f1: (test=nan) roc_auc: (test=0.571) total time= 2.0min\n",
      "[CV 2/2] END alpha=1.0, gamma=0.1, lambda=1.0, learning_rate=0.2; f1: (test=nan) roc_auc: (test=0.566) total time= 2.0min\n",
      "[CV 1/2] END alpha=0.1, gamma=1.0, lambda=1.0, learning_rate=0.2; f1: (test=nan) roc_auc: (test=0.573) total time= 1.3min\n",
      "[CV 2/2] END alpha=0.1, gamma=1.0, lambda=1.0, learning_rate=0.2; f1: (test=nan) roc_auc: (test=0.552) total time= 1.3min\n",
      "[CV 1/2] END alpha=0.01, gamma=0.01, lambda=1.0, learning_rate=0.01; f1: (test=nan) roc_auc: (test=0.576) total time= 2.9min\n",
      "[CV 2/2] END alpha=0.01, gamma=0.01, lambda=1.0, learning_rate=0.01; f1: (test=nan) roc_auc: (test=0.548) total time= 2.9min\n",
      "[CV 1/2] END alpha=0.01, gamma=1.0, lambda=0.1, learning_rate=0.2; f1: (test=nan) roc_auc: (test=0.559) total time= 1.3min\n",
      "[CV 2/2] END alpha=0.01, gamma=1.0, lambda=0.1, learning_rate=0.2; f1: (test=nan) roc_auc: (test=0.552) total time= 1.3min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.2, 'lambda': 1.0, 'gamma': 1.0, 'alpha': 1.0}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor(objective='binary:logistic')  # Set objective for regression\n",
    "\n",
    "# Define the hyperparameter grid to search\n",
    "params_dict = {'learning_rate': [0.01, 0.1, 0.2],\n",
    "               'gamma': [0.01, 0.1, 1.0],\n",
    "               'lambda': [0.01, 0.1, 1.0],\n",
    "               'alpha': [0.01, 0.1, 1.0],\n",
    "              }\n",
    "\n",
    "scoring = {\n",
    "    'f1': make_scorer(f1_score, average='micro'),\n",
    "    'roc_auc': make_scorer(roc_auc_score, multi_class='ovr', average='micro'),\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    xgb_model,\n",
    "    param_distributions=params_dict,\n",
    "    scoring=scoring,\n",
    "    refit='f1', \n",
    "    cv=2,\n",
    "    verbose=3)\n",
    "    \n",
    "search.fit(X_train_t, y_train_t)\n",
    "\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1fa6e2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_param = {'learning_rate': 0.2, 'lambda': 1.0, 'gamma': 1.0, 'alpha': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "360155b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB_model(X_train, X_test, y_train, y_test, opt_params):\n",
    "    xgb_model = xgb.XGBRegressor(objective='binary:logistic', \n",
    "                                reg_lambda=opt_params['lambda'], \n",
    "                                alpha=opt_params['alpha'], \n",
    "                                learning_rate=opt_params['learning_rate'], \n",
    "                                gamma=opt_params['gamma'],\n",
    "                                eval_metric='rmse')\n",
    "    \n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    predictions_prob = xgb_model.predict(X_test)\n",
    "\n",
    "    predictions_binary = (predictions_prob > 0.5).astype(int)\n",
    "    \n",
    "    f1 = f1_score(y_test.values.flatten(), predictions_binary.flatten(), average='micro')\n",
    "    print('F1 Score:', f1)\n",
    "\n",
    "    auc_roc = roc_auc_score(y_test.values.flatten(), predictions_prob.flatten(), average='micro')\n",
    "    print('AUC/ROC:', auc_roc)\n",
    "    \n",
    "    return [f1, auc_roc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f71f8735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5748735244519393\n",
      "AUC/ROC: 0.5991152231699481\n"
     ]
    }
   ],
   "source": [
    "metrics = XGB_model(X_train_t, X_test_t, y_train_t, y_test_t, opt_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d790a7",
   "metadata": {},
   "source": [
    "## Appending\n",
    "\n",
    "The second method is to enlarge the English dataframe by adding the Dutch versions as new rows in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4a511f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = pd.read_csv('processed_data_english_no_lowercasing.csv')\n",
    "nl = pd.read_csv('processed_data_dutch_no_lowercasing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dddb4461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well right woke midday nap Its sort weird ever...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well stream consciousness essay used thing lik...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>open keyboard button push The thing finally wo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cant believe Its really happening pulse racing...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well good old stream consciousness assignment ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>motivated day day basis need provide little fa...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>son biggest part life without reckless person ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>kid grandkids keep motivated everyday inspire ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>biggest drive earn money retire beach schedule...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>People never give cause life cruel strong enem...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2963 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   TEXT  cEXT  cNEU  cAGR  \\\n",
       "0     Well right woke midday nap Its sort weird ever...     0     1     1   \n",
       "1     Well stream consciousness essay used thing lik...     0     0     1   \n",
       "2     open keyboard button push The thing finally wo...     0     1     0   \n",
       "3     cant believe Its really happening pulse racing...     1     0     1   \n",
       "4     Well good old stream consciousness assignment ...     1     0     1   \n",
       "...                                                 ...   ...   ...   ...   \n",
       "2958  motivated day day basis need provide little fa...     1     0     0   \n",
       "2959  son biggest part life without reckless person ...     1     1     0   \n",
       "2960  kid grandkids keep motivated everyday inspire ...     1     0     1   \n",
       "2961  biggest drive earn money retire beach schedule...     0     0     0   \n",
       "2962  People never give cause life cruel strong enem...     1     1     0   \n",
       "\n",
       "      cCON  cOPN  \n",
       "0        0     1  \n",
       "1        0     0  \n",
       "2        1     1  \n",
       "3        1     0  \n",
       "4        0     1  \n",
       "...    ...   ...  \n",
       "2958     1     1  \n",
       "2959     0     0  \n",
       "2960     1     0  \n",
       "2961     0     0  \n",
       "2962     0     0  \n",
       "\n",
       "[2963 rows x 6 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b628f221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT_NL</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nou moment net wakker middagdutje Het beetje r...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nou gaan stroom bewustzijn essay deed soort di...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Een open toetsenbord knoppen drukken Het ding ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>geloven Het gebeurt echt Mijn pol raast gek Du...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Welnu weer goede oude stroom bewustzijnstoewij...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>word dagelijks gemotiveerd noodzaak kleine gez...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>Mijn zoon grootste deel leven gewoon roekeloze...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>Mijn kinderen kleinkinderen houden elke dag ge...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>Mijn grootste drijfveer geld verdienen zodat p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>Mensen nooit opgeven leven grootste deel tijd ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2963 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT_NL  cEXT  cNEU  cAGR  \\\n",
       "0     Nou moment net wakker middagdutje Het beetje r...     0     1     1   \n",
       "1     Nou gaan stroom bewustzijn essay deed soort di...     0     0     1   \n",
       "2     Een open toetsenbord knoppen drukken Het ding ...     0     1     0   \n",
       "3     geloven Het gebeurt echt Mijn pol raast gek Du...     1     0     1   \n",
       "4     Welnu weer goede oude stroom bewustzijnstoewij...     1     0     1   \n",
       "...                                                 ...   ...   ...   ...   \n",
       "2958  word dagelijks gemotiveerd noodzaak kleine gez...     1     0     0   \n",
       "2959  Mijn zoon grootste deel leven gewoon roekeloze...     1     1     0   \n",
       "2960  Mijn kinderen kleinkinderen houden elke dag ge...     1     0     1   \n",
       "2961  Mijn grootste drijfveer geld verdienen zodat p...     0     0     0   \n",
       "2962  Mensen nooit opgeven leven grootste deel tijd ...     1     1     0   \n",
       "\n",
       "      cCON  cOPN  \n",
       "0        0     1  \n",
       "1        0     0  \n",
       "2        1     1  \n",
       "3        1     0  \n",
       "4        0     1  \n",
       "...    ...   ...  \n",
       "2958     1     1  \n",
       "2959     0     0  \n",
       "2960     1     0  \n",
       "2961     0     0  \n",
       "2962     0     0  \n",
       "\n",
       "[2963 rows x 6 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f031a4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nl = nl.rename(columns={'TEXT_NL': 'TEXT'})\n",
    "concat_df = pd.concat([eng, nl], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6673f880",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_a = concat_df['TEXT'].tolist()\n",
    "y = concat_df[['cEXT', 'cNEU', 'cAGR', 'cCON', 'cOPN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2804d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(corpus_a, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4f4ab168",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()  \n",
    "\n",
    "# for Ext\n",
    "X_train_a = tfidf.fit_transform(X_train_a)\n",
    "X_test_a = tfidf.transform(X_test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "930dd7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV 1/2] END alpha=0.1, gamma=1.0, lambda=1.0, learning_rate=0.01; f1: (test=nan) roc_auc: (test=0.558) total time= 1.7min\n",
      "[CV 2/2] END alpha=0.1, gamma=1.0, lambda=1.0, learning_rate=0.01; f1: (test=nan) roc_auc: (test=0.562) total time= 1.8min\n",
      "[CV 1/2] END alpha=1.0, gamma=0.01, lambda=0.1, learning_rate=0.2; f1: (test=nan) roc_auc: (test=0.577) total time= 1.8min\n",
      "[CV 2/2] END alpha=1.0, gamma=0.01, lambda=0.1, learning_rate=0.2; f1: (test=nan) roc_auc: (test=0.572) total time= 1.8min\n",
      "[CV 1/2] END alpha=0.1, gamma=0.1, lambda=0.01, learning_rate=0.2; f1: (test=nan) roc_auc: (test=0.574) total time= 1.4min\n",
      "[CV 2/2] END alpha=0.1, gamma=0.1, lambda=0.01, learning_rate=0.2; f1: (test=nan) roc_auc: (test=0.572) total time= 1.5min\n",
      "[CV 1/2] END alpha=1.0, gamma=0.01, lambda=0.01, learning_rate=0.2; f1: (test=nan) roc_auc: (test=0.573) total time= 1.9min\n",
      "[CV 2/2] END alpha=1.0, gamma=0.01, lambda=0.01, learning_rate=0.2; f1: (test=nan) roc_auc: (test=0.573) total time= 1.8min\n",
      "[CV 1/2] END alpha=1.0, gamma=0.01, lambda=0.1, learning_rate=0.01; f1: (test=nan) roc_auc: (test=0.556) total time= 1.9min\n",
      "[CV 2/2] END alpha=1.0, gamma=0.01, lambda=0.1, learning_rate=0.01; f1: (test=nan) roc_auc: (test=0.562) total time= 2.0min\n",
      "[CV 1/2] END alpha=0.01, gamma=0.01, lambda=1.0, learning_rate=0.01; f1: (test=nan) roc_auc: (test=0.558) total time= 1.9min\n",
      "[CV 2/2] END alpha=0.01, gamma=0.01, lambda=1.0, learning_rate=0.01; f1: (test=nan) roc_auc: (test=0.563) total time= 1.9min\n",
      "[CV 1/2] END alpha=0.01, gamma=0.1, lambda=1.0, learning_rate=0.01; f1: (test=nan) roc_auc: (test=0.556) total time= 1.9min\n",
      "[CV 2/2] END alpha=0.01, gamma=0.1, lambda=1.0, learning_rate=0.01; f1: (test=nan) roc_auc: (test=0.563) total time= 1.9min\n",
      "[CV 1/2] END alpha=0.01, gamma=0.01, lambda=1.0, learning_rate=0.2; f1: (test=nan) roc_auc: (test=0.574) total time= 1.6min\n",
      "[CV 2/2] END alpha=0.01, gamma=0.01, lambda=1.0, learning_rate=0.2; f1: (test=nan) roc_auc: (test=0.576) total time= 1.6min\n",
      "[CV 1/2] END alpha=0.01, gamma=0.1, lambda=0.01, learning_rate=0.1; f1: (test=nan) roc_auc: (test=0.574) total time= 1.5min\n",
      "[CV 2/2] END alpha=0.01, gamma=0.1, lambda=0.01, learning_rate=0.1; f1: (test=nan) roc_auc: (test=0.581) total time= 1.4min\n",
      "[CV 1/2] END alpha=0.1, gamma=0.01, lambda=1.0, learning_rate=0.01; f1: (test=nan) roc_auc: (test=0.557) total time= 1.9min\n",
      "[CV 2/2] END alpha=0.1, gamma=0.01, lambda=1.0, learning_rate=0.01; f1: (test=nan) roc_auc: (test=0.562) total time= 1.9min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01, 'lambda': 1.0, 'gamma': 1.0, 'alpha': 0.1}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor(objective='binary:logistic')  # Set objective for regression\n",
    "\n",
    "# Define the hyperparameter grid to search\n",
    "params_dict = {'learning_rate': [0.01, 0.1, 0.2],\n",
    "               'gamma': [0.01, 0.1, 1.0],\n",
    "               'lambda': [0.01, 0.1, 1.0],\n",
    "               'alpha': [0.01, 0.1, 1.0],\n",
    "              }\n",
    "\n",
    "scoring = {\n",
    "    'f1': make_scorer(f1_score, average='micro'),\n",
    "    'roc_auc': make_scorer(roc_auc_score, multi_class='ovr', average='micro'),\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    xgb_model,\n",
    "    param_distributions=params_dict,\n",
    "    scoring=scoring,\n",
    "    refit='f1', \n",
    "    cv=2,\n",
    "    verbose=3)\n",
    "     \n",
    "\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6771326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_param_a = {'learning_rate': 0.01, 'lambda': 1.0, 'gamma': 1.0, 'alpha': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2f94c113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5581787521079258\n",
      "AUC/ROC: 0.580366337475164\n"
     ]
    }
   ],
   "source": [
    "metrics_a = XGB_model(X_train_a, X_test_a, y_train_a, y_test_a, opt_param_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaf8f62",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We investigated both cross-lingual and multi-lingual models. The performance metrics for the cross-lingual model can be seen in the table below. Besides, the results of part 2 are added for the purpose of comparing monolingual models to multi-lingual models.\n",
    "\n",
    "\n",
    "|              | F1 score | ROC AUC | \n",
    "| :----------: | :--: | :--: |\n",
    "| Trained and tested on English      |   0.537605\t   |  0.561213\t   |\n",
    "| Trained on English, tested on Dutch          |  0.504421  |  0.525026\t    |\n",
    "| Trained on Dutch, tested on English   |  0.545595   |  0.563599\t     |\n",
    "\n",
    "Besides the cross-lingual models, we also investigate the potential of multi-lingual models. The performance metrics of these models can be found below:\n",
    "\n",
    "\n",
    "|              | F1 score | ROC AUC | \n",
    "| :----------: | :--: | :--: |\n",
    "| Concatenating      |   0.574873\t   |  0.599115\t   |\n",
    "| Appending         |  0.558178  |  0.580366\t    |\n",
    "\n",
    "\n",
    "\n",
    "For the cross-lingual models, we trained the XGBoost model with English text and validated it on Dutch text. This yielded an F1 score of only 0.504. This score seems rather low, indicating that a cross-lingual model with English as the base is not very good at predicting when given Dutch text. \n",
    "\n",
    "Vice versa, we also trained a Dutch model and validated it on English data, which yielded an F1 score of 0.545. Again, this score is rather low indicating that also a Dutch model is not very good at predicting when given an English text.\n",
    "Remarkable is however the fact that the Dutch-English model outperforms the English-Dutch model significantly, although the difference is small. The model clearly finds some characteristics in the Dutch text that it can better apply to English text than vice versa. As presented in the data analysis part, the average sentence length for Dutch was longer than for English. This might imply that the model simply gets more data when receiving the Dutch text as opposed to the English text. \n",
    "\n",
    "All in all, the capabilities of XGBoost as cross-lingual model are very limited. Performances indicate that they are only slightly better than random guessing (F1 > 0.5). Document size might however positively affect the performance. Contrasting, it however works better than when the model has been trained and tested on only English text.\n",
    "\n",
    "For the multilingual approaches, we first enlarged the texts by concatenating the English and Dutch versions of the text together. This model yielded an F1 of 0.574. Again this seems rather low, indicating that XGBoost cannot predict very well when it receives multiple versions of the same text at once.\n",
    "\n",
    "With the approach of appending the Dutch texts to the data, the model yielded an F1 of 0.558. This indicates that this approach does also not very well for predicting. \n",
    "\n",
    "Comparing the two, we can however see that XGBoost prefers having more words per input over having more data. XGBoost thus sees is better able to see certain aspects in the text if it receives all text at once. This might imply that there is some similarity in the English and Dutch languages that the model can use to make better predictions. This seems logical seen the shared Germanic roots of both the Dutch and English language.\n",
    "\n",
    "Although both the performances of cross-lingual and multilingual approaches are mediocre, it can be identified that XGBoost shows more potential as multilingual model than as cross-lingual model.\n",
    "\n",
    "## Comparison to part 2 \n",
    "All in all, we can identify that inputting multiple languages at once does not make XGBoost a great predictor as results are only slightly better than random guessing (F1 > 0.5). It again highlights the inherently difficult nature of predicting texts. When comparing it however to the findings of part 2, we can see a significant increase. XGBoost is increasingly better at predicting if it is considered as cross-lingual or multilingual model. Here, XGBoost clearly prefers multiple languages given at once as input. This implies that, despite the difficulties in text predictions, the models can be improved by adding Dutch and English texts together. This also highlights the commonalities in the languages due to similar roots that the models can profit from as it yields extra information to the model.\n",
    "\n",
    "\n",
    "\n",
    "## Comparison between DL and ML approaches\n",
    "Comparing the machine learning approach to the deep learning approach, again some interesting findings are revealed. Firstly, regarding the cross-lingual modelling, it can be identified that both the monolingual BERT as a deep learner and XGBoost display similar performance when they are trained on English texts and validated on Dutch texts. Both appear to display performance that is only slightly better than random guessing. However, BERT always performs a little better than XGBoost. This finding is interesting as the deep learning approaches outperformed the machine learners in part 2 of the assignment when they were only trained and tested on English texts. There is no difference between deep learning and machine learning methods. More interestingly, both models show an increase in performance when they are trained on Dutch texts and validated on English texts. There are linguistic nuances of the Dutch language which then can be applied to the English language, but not vice versa. Both approaches acknowledge this and use this to their advantage, hence the higher performance when trained on the Dutch language. The usage of BERT and XGBoost for cross-lingual modelling is however debatable as both show performance similar to random guessing. The introduction of mBERt as an alternative deep learning method however is very different from BERT, showing superior performance to both BERT and XGBoost as cross-lingual models. The multilingual NLP nature and specific architecture of mBERT clearly give an advantage over the machine learning approach. As such, only when deep learners have a compatible architecture, they are able to outperform machine learners. Otherwise, machine learners and deep learners show comparable performances, indicating the increased complexity of having multiple languages instead of one.\n",
    "\n",
    "Regarding the multilingual modelling, again the machine learner and deep learner show similar performances, with the deep learner only performing slightly better than the deep learner. Most noticeable here is that for the machine learners, the performance increased significantly as opposed to part 2, whereas the performance of the deep learners decreased as opposed to part 2. The inclusion of extra languages thus is more beneficial for the machine learners than for the deep learners. Nevertheless, deep learners still outperform machine learners, showing that their architectures are more suitable for text classification than standard machine learners.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
